{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all the STAR counts from GDC - Matched normal samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dataframes_list = []\n",
    "# Get the list of all directories in the current directory\n",
    "directories = [d for d in os.listdir('.') if os.path.isdir(d)]\n",
    "\n",
    "# Loop over each directory\n",
    "for directory in directories:\n",
    "    dir_path = os.path.join('.', directory)  # Get the full path of the directory\n",
    "    subdirectories = [d for d in os.listdir(dir_path) if os.path.isdir(os.path.join(dir_path, d))]\n",
    "\n",
    "    # Loop over each subdirectory\n",
    "    for sub_dir in subdirectories:\n",
    "        sub_dir_path = os.path.join(dir_path, sub_dir)  # Get the full path of the subdirectory\n",
    "\n",
    "        # Get the list of all files in the current subdirectory\n",
    "        files = os.listdir(sub_dir_path)\n",
    "\n",
    "        # Filter for .tsv files and process them\n",
    "        tsv_files = [item for item in files if item.endswith('augmented_star_gene_counts.tsv')][0]\n",
    "        \n",
    "        file_path = os.path.join(sub_dir_path, tsv_files)  # Get the full path of the .tsv file\n",
    "        # Read the .tsv file with pandas, selecting the second and fourth columns\n",
    "        \n",
    "        df = pd.read_csv(file_path, sep='\\t', skiprows=1, usecols=['gene_id', 'unstranded'])\n",
    "        \n",
    "        # Rename the columns\n",
    "        df.columns = ['gene_id', tsv_files]\n",
    "        df.dropna(inplace=True)\n",
    "        df.set_index('gene_id', inplace=True, drop=True)\n",
    "        dataframes_list.append(df)\n",
    "        \n",
    "merged_df = pd.concat(dataframes_list, join='inner',axis=1)\n",
    "\n",
    "merged_df.to_csv('TCGA_normal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TCGA_normal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the first few row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([0,1,2,3],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('TCGA_normal.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all the sample sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory where the files are stored (assuming current directory for this example)\n",
    "directory = '.'\n",
    "\n",
    "# Initialize an empty list to store file paths\n",
    "sample_sheet_files = []\n",
    "\n",
    "# Loop through the files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if \"gdc_sample_sheet\" in filename and filename.endswith(\".tsv\"):\n",
    "        # Add the full path of the file to the list\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        sample_sheet_files.append(file_path)\n",
    "\n",
    "# Concatenate all the files into a single dataframe\n",
    "df_concatenated = pd.concat((pd.read_csv(file, sep='\\t') for file in sample_sheet_files), ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the concatenated dataframe\n",
    "df_concatenated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary to map the filename (current column name of the 'TCGA_normal.csv') to sample name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappingDict = {}\n",
    "for ind, row in df_concatenated.iterrows():\n",
    "    if row[1] not in mappingDict:\n",
    "        mappingDict[row[1]] = row[6]\n",
    "    else:\n",
    "        print(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnamelst = ['gene_id']\n",
    "for i in df.columns[1:]:\n",
    "    colnamelst.append(mappingDict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace column name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = colnamelst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('TCGA_normal_.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
